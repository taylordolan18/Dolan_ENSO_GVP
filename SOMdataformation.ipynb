{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c4ada0-59b8-4040-8f81-81af01496547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "maxuwind=-9999999  #This step is done so that later in the code you can normalize the data for easy comparison of variables.          \n",
    "minuwind=999999    #You want to set the max to a really low number and the min to a really high number so that when you loop through the data you can essentially \"beat\" those values.\n",
    "\n",
    "maxvwind=-9999999 #You will want to establish a max/min varible for each variable in your dataset that you are pulling (ex. If you want temperature make mintemp and maxtemp)\n",
    "minvwind=999999\n",
    "\n",
    "maxmslp=-9999999\n",
    "minmslp=999999\n",
    "\n",
    "\n",
    "mslpdata=np.empty([0,5916])  # Here I am making the new array that my flattened arrays will be placed. I had 3D arrays that needed to be flattened. \n",
    "uwinddata=np.empty([0,5916])\n",
    "vwinddata=np.empty([0,5916])\n",
    "alldata = np.empty([0,5916])\n",
    "\n",
    "months=['01']         #Here I am selected the month of data I want. All data files are named MMYYYY.nc. You cna add multiple months here like so: ['01','02']\n",
    "for m in months:\n",
    "\n",
    "    files = glob.glob('DATA_ERA5\\\\'+m+'*',  #All data files in the form MMYYYY are in the folder 'DATA_ERA5'. This is simply the place your data is stored.\n",
    "                   recursive = True)\n",
    "\n",
    "    for f in files:\n",
    "        ds= xr.open_dataset(f, engine='netcdf4')    #All the files I am using are xarrays and NetCDFs \n",
    "        \n",
    "        mslp = (ds['msl'].values)/100\n",
    "        lon = ds['longitude'].coarsen(longitude=4).mean()   #I define and pull the variables here. I use the lat and lon later in the code for plotting purposes \n",
    "        lat = ds['latitude'].values\n",
    "        uwind = (ds['u10'].values)*1.94\n",
    "        vwind = (ds['v10'].values)*1.94  #Conversions I do here \n",
    "        \n",
    "        mslpraw=ds['msl'].coarsen(longitude=4).mean().coarsen(latitude=1).mean()/100  #coarsen is used to reduce the amount of data points. Here I am coarsening the longitude only by a factor of 4.\n",
    "        uwindraw=ds['u10'].coarsen(longitude=4).mean().coarsen(latitude=1).mean()*1.94 #you need to coarsen each variable (ex. temp, relative humidity. etc) the same. Coarsening must result in an even number  \n",
    "        vwindraw=ds['v10'].coarsen(longitude=4).mean().coarsen(latitude=1).mean()*1.94 #By even I mean, if you have 272 longitude points you can not coarsen by 5 because the ending value is not a whole number\n",
    "#The conversions that are done in the coarsen step are NEEDED!!!! DO NOT FORGET THEM\n",
    "    \n",
    "        #generate the empty array that is the numnber of days in the month and the number of degrees of longitude*latatiude\n",
    "        nday =int((ds['time'].size)) # if you want to have just one hour of the day divide by 24, however, I want all the hours so no division here\n",
    "        nx = int((ds['latitude'].size)/1)\n",
    "        ny = int((ds['longitude'].size)/4) # whatever factor you coarsen your data by you will want to divide the same variable here by that factor.\n",
    "        mslparr = np.empty((nday, nx*ny))\n",
    "        uwindarr = np.empty((nday, nx*ny))  #this array will house the flattened data so you need one for each vairable! I am getting my 3D data to be 2D\n",
    "        vwindarr = np.empty((nday, nx*ny))\n",
    "\n",
    "        for i in range(nday):   #loop here is done for each day \n",
    "            \n",
    "            mslparr[i,:]= mslpraw[i,:,:].stack(point=[\"latitude\", \"longitude\"])  #the stack function is reducing the dimensions of the original array (3D to 2D)\n",
    "            uwindarr[i,:]= uwindraw[i,:,:].stack(point=[\"latitude\", \"longitude\"])\n",
    "            vwindarr[i,:]= vwindraw[i,:,:].stack(point=[\"latitude\", \"longitude\"])\n",
    "            \n",
    "        mslpdata=np.append(mslpdata,mslparr,axis=0)   #you will use append here to place the flattened data into the arrya you made earlier\n",
    "        uwinddata=np.append(uwinddata,uwindarr,axis=0)\n",
    "        vwinddata=np.append(vwinddata,vwindarr,axis=0)\n",
    "for i in range(23064):\n",
    "    mslpdata[i,:] =mslpdata[i,:]-np.mean(mslpdata[i,:])    #the 23604 is from the fact that I am pulling Jnauary data so 31 days for 31 years and all 24 hours (31*31*24 == number of rows)\n",
    "print(mslpdata)\n",
    "#^^^the above code is used to get the anomalies in the MSLP. You can do this for any variable you have just make sure you loop through all the rows \n",
    "for i in range(23064):\n",
    "    minmslp=min(minmslp,np.min(mslpdata[i,:]))\n",
    "    maxmslp=max(maxmslp,np.max(mslpdata[i,:]))\n",
    "for i in range(23064):\n",
    "    minuwind=min(minuwind,np.min(uwinddata[i,:]))   #this code snipbits are used to determine the max and min of each row for each vairable. Each row correlates to one hour of the day for all 31 years and 31 days and 24 hours\n",
    "    maxuwind=max(maxuwind,np.max(uwinddata[i,:]))\n",
    "for i in range(23064):\n",
    "    minvwind=min(minvwind,np.min(vwinddata[i,:]))\n",
    "    maxvwind=max(maxvwind,np.max(vwinddata[i,:]))\n",
    "print('##########################################')\n",
    "mslp_factor=100./(maxmslp-minmslp)     #you are generating the normalization factor here. If you use wind, make sure to use the largest normalization factor for both the U/V wind. Do not use differnet values.\n",
    "uwind_factor=100./(maxuwind-minuwind)\n",
    "vwind_factor=100./(maxvwind-minvwind)\n",
    "print('##########################################')\n",
    "mslpdata=mslpdata*mslp_factor   #multiple the normalization factor with the correlating variable \n",
    "uwinddata=uwinddata*uwind_factor  #here the uwind facotr was largest so both get multiplied by it \n",
    "vwinddata=vwinddata*uwind_factor\n",
    "print('##########################################')\n",
    "alldata = np.hstack((mslpdata, uwinddata, vwinddata))   #the all data array is the final array and the input for the SOM. You stack horrizontally (add to the end of the row) the data so each row is one hour and all the data associated with that hour."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
